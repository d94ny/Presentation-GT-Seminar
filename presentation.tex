\documentclass{beamer}
 

% ===========================================================
% Setup
\usepackage[T1]{fontenc}
%\usepackage[utf8]{inputenc}
\usepackage{subfig}
\usepackage{amssymb,enumerate,tikz, tkz-berge}
\usetikzlibrary{automata, positioning}
%\usepackage{sgame}
\usepackage{sgamevar}


% ===========================================================
% Customization
\newcommand{\eq}[1]{\underline{#1}}
\usepackage{lmodern}
%\usefonttheme[onlymath]{serif}
\usefonttheme{professionalfonts}
\usetheme{boxes}
\usecolortheme{orchid}
\definecolor{eth}{rgb}{0.1215686275,0.2509803922,0.4784313725}
\definecolor{eth2}{rgb}{0.2352941176, 0.3529411765, 0.05882352941}
\definecolor{eth3}{rgb}{0, 0.4117647059, 0.7058823529}
\definecolor{eth7}{rgb}{0.6588235294, 0.1960784314, 0.1764705882}
\definecolor{eth9}{rgb}{0.5843137255, 0.3764705882, 0.07450980392}
\definecolor{eth10}{rgb}{0.5098039216, 0.7450980392, 0.1176470588}
\colorlet{beamer@blendedblue}{eth}
\setcounter{tocdepth}{1}
\setbeamercolor*{block title}{fg=white, bg=eth2}
\setbeamercolor*{block title alert}{fg=white, bg=eth7}
\setbeamercolor*{block title alertblock}{fg=white, bg=eth7}
\setbeamercolor*{block title example}{fg=white, bg=eth3}
\setbeamercolor*{block title exampleblock}{fg=white, bg=eth3}
\addtobeamertemplate{proof begin}{\setbeamercolor{block title}{fg=white, bg=eth9}}{}
 
 
% ===========================================================
% Presentation Metadata
\title{Stochastic Uncoupled Dynamics\\and Nash Equilibrium}
%\subtitle{Sergiu Hart, Andreu Mas-Colell}
\author{Daniel Balle}
\institute{ETH Z\"{u}rich}
\date{May 2017}
\logo{\includegraphics[width=12.8mm]{eth_logo_kurz_pos_13.pdf}\hspace{6pt}}

%\AtBeginSection[]
%{
%  \begin{frame}
%    \frametitle{Table of Contents}
%    \tableofcontents[currentsection]
%  \end{frame}
%}
 
  
% ===========================================================
\begin{document}
\beamertemplatenavigationsymbolsempty
 
\frame{\titlepage}
 
\section{Introduction}

\begin{frame}
    \frametitle{Introduction}
	\begin{definition}[Uncoupledness]
        A dynamic process in a game is called \textbf{uncoupled}
        if the strategy of each player does not depend on the
        utility/payoff function of other players.
    \end{definition}
    \pause
    \begin{alertblock}{Hart and Mas-Colell '03}
%        There are games with unique Nash equilibria for which \textbf{no}
%        deterministic uncoupled dynamics leads to a Nash Equilibrium.
        \it There are no deterministic uncoupled stationary dynamics that guarantee almost sure
        convergence to pure Nash equilibria in all games where such equilibria exist.
    \end{alertblock}
\end{frame}
    
\begin{frame}
    \frametitle{Introduction}
    \framesubtitle{The Bad News}
    \vspace{-20pt}
    \begin{figure}[h]
    \centering
    \begin{game}{3}{3}
            \>  $\alpha$ \>  $\beta$  \> $\gamma$ \\
         $\alpha$    \>  $1, 0$ \> $0, 1$ \> $1,0$\\
         $\beta$      \>  $0, 1$ \> $1, 0$ \> $1, 0$\\
         $\gamma$ \>  $0, 1$ \> $0, 1$ \> $1, 1$\\
    \end{game}
    \caption{A simple two-player game $U$}
    \end{figure}
    \vspace{-10pt}
    \begin{exampleblock}{Observation}
        In each action combination $a$ at least one of the two players is best-replying.
    \end{exampleblock}
    \pause
    \begin{lemma}
        Under uncoupled dynamics $f$, if player $i$ is best-replying in state $a$ he will play the same move again.
    \end{lemma}
\end{frame}

\begin{frame}
    \frametitle{Introduction}
    \framesubtitle{The Bad News}
    \vspace{-20pt}
    \begin{figure}[h]
    \centering
    \begin{game}{3}{3}
            \>  $\alpha$ \>  $\beta$  \> $\gamma$ \\
         $\alpha$    \> {\color{eth7}$1, \mathbf{2}$} \> $0, 1$ \> $1,0$\\
         $\beta$      \>  $0, 1$ \> $1, 0$ \> $1, 0$\\
         $\gamma$ \>  $0, 1$ \> $0, 1$ \> {\color{eth7}$1, \mathbf{0}$}\\
    \end{game}
    \caption{Another two-player game $U'$}
    \label{fig:example1}
    \end{figure}
    \vspace{-10pt}
    \begin{overprint}
        \onslide<1>
        \begin{proof}[\proofname\ 1/2]
            \let\qed\relax
            \begin{itemize}
                \item Pick some $a$ where player 1 is best-replying
                \item Create a new game $U' = (u^1, \bar{u}^2)$ such that $a$
                    becomes the unique Nash equilibria
            \end{itemize}
        \end{proof}
        \onslide<2>
        \begin{proof}[\proofname\ 2/2]
            %\let\qed\relax
            \begin{itemize}
                \item The dynamics $f$ converge and thus
                    neither player will move away from $a$
                \item Yet by uncoupledness $f^1(U) = f^1(U')$
            \end{itemize}
        \end{proof}
    \end{overprint}
%
%	Since our strategy mapping converges and is 1-recall neither player will choose
%	a different action at time $t+1$. Yet by uncoupledness the strategy of player 1 is
%	independent of the utility function of player 2, and thus he will not move in the
%	original game $U$ either.
\end{frame}

\begin{frame}
    \frametitle{Introduction}
    \framesubtitle{The Bad News}
    \vspace{-20pt}
    \begin{figure}[h]
    \centering
    \begin{game}{3}{3}
            \>  $\alpha$ \>  $\beta$  \> $\gamma$ \\
         $\alpha$    \>  $1, 0$ \> $0, 1$ \> $1,0$\\
         $\beta$      \>  $0, 1$ \> $1, 0$ \> $1, 0$\\
         $\gamma$ \>  $0, 1$ \> $0, 1$ \> $1, 1$\\
    \end{game}
    \caption{The initial two-player game $U$}
    \end{figure}
    \vspace{-10pt}
    \begin{exampleblock}{Observation 2}
        In any action combination $a$ in which only player $i$ plays $\gamma$, player
        $i$ is not best-replying and thus player $j$ is.
    \end{exampleblock}
    \pause
    \begin{proof}[Conclusion]
        It follows that the state $(\gamma, \gamma)$ can
        never be reached when starting from any other state.
    \end{proof}
\end{frame}


\begin{frame}
    \frametitle{Introduction}
    \framesubtitle{But ...}
    \begin{center}
        What if players could \textbf{remember} previous plays?\\
        What if they had \textbf{memories}?
    \end{center}
\end{frame}

%\section{Models \& Concepts}
%\subsection{Static Setup}

%\begin{frame}
%    \frametitle{Static Setup}
%    \framesubtitle{you already know this}
%	\begin{definition}[Static game]
%		\begin{itemize}
%			\item $N \geq 2$ players denoted by $i \in \{1, 2, ..., N\}$
%			\item A finite set of actions $A^i$ for each player $i$
%			\item The set of action combinations $A := A^1 \times A^2 \times ... \times A^N$
%			\item A payoff (or utility) function $u^i : A \to \mathbb{R}$ for each
%				player $i$
%		\end{itemize}
%		We then identify a game by its payoff functions $U := (u^1, ..., u^N)$.
%	\end{definition}
%\end{frame}

%\begin{frame}
%    \frametitle{Static Setup}
%    \framesubtitle{you already know this}
%	\begin{definition}[randomized or mixed actions]
%		Player $i$ assigns a
%		probability $x^i(a)$ to each action $a \in A^i$.
%		\begin{itemize}
%			\item The set of all mixed actions for player $i$ is $\Delta(A^i)$
%			\item We denote by $\Delta := \Delta(A^1) \times ... \times \Delta(A^N)$
%				the set of randomized action combinations or $N$-tuples.
%			\item The payoff function is multi-linearly extended to $u^i : \Delta \to \mathbb{R}$
%		\end{itemize}
%	\end{definition}
%\end{frame}

%\begin{frame}
%    \frametitle{Nash Equilibria}
%    \framesubtitle{should also look familiar}
%	\begin{definition}[best replying]
%		We say that the randomized actions $x^i \in \Delta(A^i)$ is an \emph{$\epsilon$-best reply}
%		to $x^{-i} := (x^1, ..., x^{i-1}, x^{i+1}, ..., x^N)$ if for all $y^i \in \Delta(A^i)$:
%		\[
%			u^i(x) \geq u^i(y^i, x^{-i}) - \epsilon
%		\]
%	\end{definition}
%    \pause % maybe not?
%	\begin{definition}[Nash $\epsilon$-equilibrium]
%		A \emph{Nash $\epsilon$-equilibrium} is a randomized action combination $\eq{x} =
%		(\eq{x}^1, ..., \eq{x}^N) \in \Delta$ such that each $\eq{x}^i$ is an $\epsilon$-best reply
%		to $\eq{x}^{-i}$.
%	\end{definition}
%\end{frame}

%\subsection{Dynamic Setup \& History of Play}

%\begin{frame}
%    \frametitle{Dynamic Setup}
%    \begin{definition}[History of Play]
%        For repeated play of $U$ at discrete time periods $t = 1, 2, ...$
%        \begin{itemize}
%            \item $a^i(t) \in A^i$ the action of player $i$ at time $t$
%            \item $a(t) = (a^1(t), ..., a^N(t)) \in A$ the action combination at $t$
%            \item $(a(1), ..., a(t-1)) \in H$ the history of play
%        \end{itemize}
%    \end{definition}
%    \pause
%    \begin{definition}[Strategies]
%        \begin{itemize}
%            \item $f^i : H \to \Delta(A^i)$ the \textbf{stationary} strategy of player $i$
%            \item $f(U) = (f^1(u^1), ..., f^N(u^n))$ the \textbf{uncoupled} strategy mapping for $U$
%        \end{itemize}
%    \end{definition}
%\end{frame}


\section{Recall}

\begin{frame}
    \frametitle{Recall}
    \framesubtitle{Influence from the Past}
    \begin{definition}
        A strategy has $R$\textbf{-recall} if only the last $R$ action combinations matter,
        i.e. $f^i$ is of the form $f^i(u^i; a(t-R), ..., a(t-1))$.
    \end{definition}
    \pause
    \begin{theorem}
        There exist uncoupled, 2-recall, stationary strategy mappings that
        guarantee almost sure convergence to
        pure Nash equilibria  in every game where such equilibria exist.
    \end{theorem}
\end{frame}

\begin{frame}
    \frametitle{Proof}
    \begin{definition}[State]
        A state is identified as the play of the two previous periods $(a', a) := (a(t-1), a(t)) \in A \times A$.
    \end{definition}
    \pause
    \begin{exampleblock}{Strategy $f^i$}
        \begin{itemize}
            \item if $a' = a$ and $a^i$ is a best reply of player $i$ to $a^{-i}$\\
                then player $i$ plays the same action $a^i$;
            \item otherwise player $i$ picks an action $\bar{a}^i$ uniformly at random from $A^i$
        \end{itemize}
    \end{exampleblock}
\end{frame}


\begin{frame}
    \newcommand{\hl}{\only{\color{eth7}}}
    \frametitle{Proof}
    \begin{figure}[h]\hspace*{\fill}%
    \centering%
    \renewcommand{\gamestretch}{1.25}%
    \begin{game}{2}{2}
        \>$a' = a$\>$a' \neq a$\\
         $a \in \text{PNE}$ \> {\hl<2-3>$\mathbf{S}_1$}\>{\hl<4-5>$\mathbf{S}_2$}\\
         $a \notin \text{PNE}$\> {\hl<4,7>$\mathbf{S}_4$}\>{\hl<4,6>$\mathbf{S}_3$}
    \end{game}\hspace*{\fill}%
    \caption{State space $S$ partition}%
    \label{fig:example2}%
    \end{figure}
    \vspace{-10pt}
    \pause
    \begin{overlayarea}{\textwidth}{5cm}
        \onslide*<2-3>{
        \begin{exampleblock}{Observation}
            Each state in $S_1$ is absorbing.
        \end{exampleblock}}
        \onslide*<3>{
        \begin{proof}[Strategy $f^i$]
            \let\qed\relax
            \begin{itemize}
                \item if $a' = a$ and $a^i$ is a best reply of player $i$ to $a^{-i}$\\
                    then player $i$ plays the same action $a^i$;
            \end{itemize}
        \end{proof}}
        \onslide*<4-7>{
        \begin{lemma}
            For all states $s \in S_2 \cup S_3 \cup S_4$ there is a strictly positive probability $p > 0$ to
            reach a state $s' \in S_1$ in finitely many periods. % transient state
        \end{lemma}}
        \onslide*<5>{
        \begin{proof}[$S_2$]
            \let\qed\relax
            All players randomly pick $a^i$ again $\Rightarrow (a, a) \in S_1$
        \end{proof}}
        \onslide*<6>{
        \begin{proof}[$S_3$]
            \let\qed\relax
            All players randomly pick some $\bar{a}^i$ s.t. $\bar{a} \in $ PNE $\Rightarrow (a, \bar{a}) \in S_2$
        \end{proof}}
        \onslide*<7>{
        \begin{proof}[$S_4$]
            \let\qed\relax
            Some player randomly picks $\bar{a}^i \Rightarrow (a, \bar{a}) \in S_2 \cup S_3$ 
        \end{proof}}
        \onslide*<8>{
        \begin{proof}[Conclusion]
            $f$ induces an absorbing Markov Chain over $S$.
        \end{proof}}
    \end{overlayarea}
\end{frame}

\begin{frame}
    \frametitle{Can We Go Further? }
    \begin{center}
        What about \textbf{Mixed} Nash Equilibria?
    \end{center} 
\end{frame}

\begin{frame}
    \frametitle{Mixed Equilibira}
    \begin{alertblock}{Theorem}
        \it For every small enough $\epsilon > 0$, there are no uncoupled, \textbf{finite recall}, stationary strategy
        mappings $f$ that guarantee in every game, the almost sure convergence of the behavior probabilities
        to Nash $\epsilon$-equilibria.
    \end{alertblock}
\end{frame}

\begin{frame}
    \frametitle{Proof}
    \setcounter{subfigure}{0}
	\begin{figure}[h]
	\centering
        \subfloat[$U = (u^1, u^2)$]{
		    \begin{game}{2}{2}
    	 		\>  $\alpha$ \>  $\beta$ \\
    			$\alpha$    \>  $1, 0$ \> $0, 1$\\
    			$\beta$      \>  $0, 1$ \> $1, 0$\\
            \end{game}
		}
		\qquad\qquad\qquad
        \subfloat[$U' = (u^1, \bar{u}^2)$]{
		    \begin{game}{2}{2}
    	 				\>  $\alpha$ \>  $\beta$ \\
    			$\alpha$    \>  $1, 1$ \> $0, 0$\\
    			$\beta$      \>  $0, 1$ \> $1, 0$\\
            \end{game}
        }
    \end{figure}
    \pause
    \begin{overlayarea}{\textwidth}{5cm}
        \onslide*<2>{
        \begin{exampleblock}{Observation}
            \begin{itemize}
                \item Unique equilibria in $U$ is $\eq{x}$ with $\eq{x}^i = (0.5, 0.5)$
                \item Unique equlibiria in $U'$ is $\eq{a} = (\alpha, \alpha)$
            \end{itemize}
        \end{exampleblock}}
        \onslide*<3-6>{
        \begin{proof}[Suppose $f$ exists]
            \begin{itemize}
                \item<3-> $f$ assigns $x^i(\alpha) > 0$ in both $U$ and $U'$
                \item<4-> We eventually reach the state $s = (\eq{a}, ..., \eq{a})$ in both games
                \item<5-> $f^1(s)$ should then be close to the unique Nash Equilibrium
                \item<6 | alert@6> Contradicts uncoupledness since $f^1(U;s) = f^1(U';s)$
            \end{itemize}
        \end{proof}}
    \end{overlayarea}
\end{frame}


% note about the empirical distribution?

\section{Memory}

\begin{frame}
    \frametitle{But...}
    \begin{center}
        What about if players had arbitrary \textbf{memories}?
    \end{center} 
\end{frame}

\begin{frame}
    \frametitle{Memory}
    \framesubtitle{No Continuity Restriction}
    \begin{definition}
        A player's strategy $f^i$ has finite $R$-memory if it can be implemented by a finite-state 
        automaton in $|A|^R$ states.
    \end{definition}
    \pause
    \begin{theorem}
        For every $\epsilon > 0$ there exists an uncoupled, $R$-memory,
        stationary strategy mapping that guarantees the
        almost sure convergence of the behavior probabilities to a Nash $\epsilon$-equilibrium $\eq{x}$.
    \end{theorem}
\end{frame}

% This is where stuff gets really interesting

\begin{frame}
    \frametitle{Proof}
    \framesubtitle{Buckle in}

    \begin{exampleblock}{Construction 1/2}
        % remove the 2 here
        \begin{itemize}
            \item<1-> Find some $K$ such that there is a Nash $\epsilon$-Equilibrium $y = (y^1, ..., y^N)$
		    with all probabilities being multiples of $1/K$.
            \item<2-> Define $f$ to have $R = 2K + 1$ memory.
        \end{itemize}
    \end{exampleblock}
    % what a state is
    \onslide<3->
    \begin{definition}
        \begin{itemize}
            \item<3-> The state $\tilde{s}^i$ of player $i$ are his $R$ memories
                $(a_0, a_1, ... a_{2K})$
            \item<4-> $s^i$ denotes his $2K$ most recent memories $(a_1, ..., a_{2K})$ 
            \item<5- | alert@5> Here all players will have the same memories $\tilde{s}$!
        \end{itemize}
    \end{definition}
\end{frame}

\begin{frame}
    \frametitle{Proof}
    \begin{definition}
        We denote by $z^i$ the frequency distribution of actions from player $i$
        over his $K$ most recent memories $(a_{K+1}, ..., a_{2K})$.
    \end{definition}
    \pause
    \begin{example}
        For the $K=5$ memories %$((\alpha, \beta), (\alpha, \gamma), (\gamma, \beta))$
			$((\alpha, \alpha), (\alpha, \beta), (\beta, \gamma), (\gamma, \gamma), (\gamma, \gamma))$:
        \begin{gather*}
            z^1(\alpha) = 2/5, \,\,\,\, z^1(\beta) = 1/5, \,\,\,\, z^1(\gamma) = 2/5\\
            z^2(\alpha) = 1/5, \,\,\,\, z^2(\beta) = 1/5, \,\,\,\, z^2(\gamma) = 3/5
        \end{gather*}
    \end{example}
\end{frame}

\begin{frame}
    \frametitle{Strategy $f^i$}
    \pause
    \begin{exampleblock}{if $\tilde{s} = (a_0, s)$ is not $K$-periodic (Mode I)}
        \pause
        \begin{itemize}
            \item<3-> if $s$ is $K$-periodic and
                
                \begin{itemize}
                    \item<4-> $z^i$ is a $\epsilon$-best reply to $z^{-i}$,
                    \textbf<4>{he continues his periodic play}
			
			        \item<5-> otherwise, \textbf<5>{he breaks his periodic play}
                \end{itemize}
			
			\item<6-> if $s$ is not $K$-periodic player $i$ picks a random action $\bar{a}^i$
        \end{itemize}
        \vspace{-5pt}
        \onslide<7->
        \textcolor{eth}{\noindent\rule{\textwidth}{0.7pt}}\\
        The new state of $f^i$ becomes $\tilde{s}' = (a_1, ..., a_{2K}, \bar{a})$.
    \end{exampleblock}
    \onslide<8->
    \begin{exampleblock}{if $\tilde{s} = (a_0, s)$ is $K$-periodic (Mode II)}
        \onslide<9->
        \begin{itemize}
			\item player $i$ plays the mixed action $z^i$
        \end{itemize}
        \vspace{-5pt}
        \onslide<10->
        \textcolor{eth}{\noindent\rule{\textwidth}{0.7pt}}\\
        The state of $f^i$ remains the same $\tilde{s}' = \tilde{s}$.
    \end{exampleblock}
\end{frame}

\section{Closing}
 
\end{document}
